{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 13:02:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import random\n",
    "\n",
    "from pyspark import Row, SparkConf, SparkContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# from src.core import init_spark\n",
    "from src.preprocessing.loader import load\n",
    "import re\n",
    "from pyspark.sql.functions import udf, regexp_replace, split, col, desc, collect_list, substring, avg, collect_set\n",
    "from pyspark.sql.types import StringType, DoubleType, FloatType\n",
    "from pyspark.sql.functions import concat_ws\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql.functions import size, array_intersect, when\n",
    "\n",
    "# PySPark's Word2Vec for a fixed size vectors\n",
    "from pyspark.ml.feature import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Setup\n",
    "\n",
    "Code used to facilitate data preprocessing and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'http:\\/\\/dbpedia\\.org\\/resource\\/')\n",
    "\n",
    "\n",
    "def replace_pattern(text):\n",
    "    return [pattern.sub(r' ', t) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_spark(app_name: str, executor_memory: str, executor_cores: int, driver_memory: str,\n",
    "               max_task_retries: int, max_failures: int):\n",
    "\n",
    "    conf = SparkConf()\n",
    "    conf.setAppName(app_name)\n",
    "    conf.set('spark.executor.memory', executor_memory)\n",
    "    conf.set('spark.executor.cores', executor_cores)\n",
    "    conf.set('spark.driver.memory', driver_memory)\n",
    "    conf.set('spark.task.maxFailures', max_failures)\n",
    "    conf.set('spark.task.maxTaskAttempts', max_task_retries)\n",
    "\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession(sc)\n",
    "\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1> Initialization of Spark Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 13:02:08 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "#stops any existing Spark running to allow\n",
    "spark = SparkSession.builder.appName(\"my_app1\").getOrCreate()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "df = load()\n",
    "spark = init_spark('my_app1', '4g', 6, '4g', 10, 20)\n",
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Preprocessing (Content-Based)\n",
    "\n",
    "Uses Count Vectorizer to create vectors that will be evaluated using a cosine similarity\n",
    "https://spark.apache.org/docs/latest/ml-features.html#countvectorizer\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- featuresCountVec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df.printSchema()\n",
    "# print(df.count())\n",
    "udf_replace_pattern = udf(replace_pattern, StringType())\n",
    "\n",
    "df = df.withColumn('concepts_isolated', udf_replace_pattern('concepts'))\n",
    "df = df.withColumn(\"concepts_isolated_no_brackets\", regexp_replace(\"concepts_isolated\", r\"\\[|\\]\", \"\"))\n",
    "\n",
    "df = df.withColumn('concatenated_columns',\n",
    "                   concat_ws(\" \", \"subject\", \"catalog\", \"career\", \"credit\", \"concepts_isolated_no_brackets\"))\n",
    "df = df.withColumn(\"array_features\", split(\"concatenated_columns\", \",\")  )# puts the concepts into an array for Word2Vec\n",
    "# df.select(\"array_features\").show(10, truncate=False)\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"array_features\", outputCol=\"featuresCountVec\")\n",
    "cv.binary = True\n",
    "cv.setMinDF = 2\n",
    "cv.setMinTF = 1\n",
    "model = cv.fit(df)\n",
    "result = model.transform(df)\n",
    "# result.select(\"featuresCountVec\").show(10, truncate=False)\n",
    "\n",
    "# dropping everything except the course code and the countvectorizer\n",
    "result = result.drop('ID', 'title', 'subject', 'catalog', 'career', 'credit', 'requisites', 'description', 'concepts', 'concepts_isolated', 'concepts_isolated_no_brackets', 'concatenated_columns', 'array_features')\n",
    "# result.show(10, truncate=False)\n",
    "\n",
    "# useful to see the overall columns and metadata\n",
    "result.printSchema()\n",
    "# (training, test) = result.randomSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Content Based Recommender (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return float(vec1.dot(vec2) / (vec1.norm(2) * vec2.norm(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the cosine similarity function as a UDF\n",
    "cosine_similarity_udf = udf(cosine_similarity, DoubleType())\n",
    "\n",
    "# CrossJoin the DataFrame with itself to get all pairs of rows\n",
    "df_pairs = result.alias(\"a\").crossJoin(result.alias(\"b\"))\n",
    "\n",
    "# Register the UDF\n",
    "spark.udf.register(\"cosine_similarity_udf\", cosine_similarity, DoubleType())\n",
    "\n",
    "# Calculate the cosine similarity for each pair of rows\n",
    "df_similarity = df_pairs.selectExpr(\n",
    "    \"a.code as code1\",\n",
    "    \"b.code as code2\",\n",
    "    \"cosine_similarity_udf(a.featuresCountVec, b.featuresCountVec) as similarity\"\n",
    ")\n",
    "\n",
    "# It won't display the CosineSimilarity for identical course codes\n",
    "# And won't display redundant rows (ex: COMP352 | COMP346 | 0.4\n",
    "#                                       COMP346 | COMP352 | 0.4 )\n",
    "df_similarity = df_similarity.filter(col(\"code1\") < col(\"code2\"))\n",
    "#df_similarity.printSchema()\n",
    "# df_similarity.show(50)\n",
    "\n",
    "#can set the minimum threshhold for course similarity.\n",
    "df_similarity = df_similarity.filter(col(\"similarity\") > 0)\n",
    "df_similarity = df_similarity.orderBy('similarity', ascending=False)\n",
    "# df_similarity.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_similarity.show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loads Pickled Content Based Model's Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('similarity.pkl', 'rb') as file:\n",
    "        pandas = pickle.load(file)\n",
    "        pickleDF = spark.createDataFrame(pandas)\n",
    "        pickleDF = pickleDF.orderBy(\"similarity\", ascending=True)\n",
    "        # pickleDF.show(10000)\n",
    "        # print(pickleDF.count())\n",
    "except:\n",
    "    with open('similarity.csv', 'rb') as file:\n",
    "        pandas = pd.read_csv(file)\n",
    "        pickleDF = spark.createDataFrame(pandas)\n",
    "        pickleDF.show()\n",
    "        # print(pickleDF.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation (Content Based)\n",
    "\n",
    "Using the initial dataset that uses \"ID\",'title','subject', 'catalog', 'career', 'credit', 'description','concepts', 'code, 'requisites' to create our truth values based on the idea that requisite courses that are assigned by an institution for a course should be relevant/recommended.\n",
    "Source: https://bond-kirill-alexandrovich.medium.com/precision-and-recall-in-recommender-systems-and-some-metrics-stuff-ca2ad385c5f8\n",
    "\n",
    "    \n",
    "A \"Precision\" column representing the Precision metric:\n",
    "    $$ \\frac{RecommendedCourses \\cap requisites}{RecommendedCourses}$$\n",
    "    \n",
    "A \"Recall\" column representing the Recall metric:\n",
    "    $$ \\frac{RecommendedCourses \\cap requisites}{requisites}$$\n",
    "    \n",
    "A \"F1-score\" column representing the F1-score metric:\n",
    "    $$ \\frac{(1+\\beta^2) * Precision * Recall}{\\beta^2 Precision + Recall}$$\n",
    "\n",
    "$\\beta = 1$: Precision and Recall have equal importance\n",
    "$\\beta > 1$: Recall has more importance\n",
    "$\\beta < 1$: Precision has more importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|   code|          requisites|  RecommendedCourses|\n",
      "+-------+--------------------+--------------------+\n",
      "|ACCO220|[ACCO218, ACCO213...|[CENT1100, CESF20...|\n",
      "|ACCO230|[ACCO365, COMM305...|[FINA408, FINA402...|\n",
      "|ACCO240|[COMM305, ACCO218...|[CENT1100, CESF20...|\n",
      "|ACCO310|[COMM305, ACCO218...|[CHEM242, COMP478...|\n",
      "|ACCO320|[ACCO400, ACCO460...|[ECON643, GPWL939...|\n",
      "|ACCO330|[COMM305, ACCO218...|[BIOL322, COMP476...|\n",
      "|ACCO340|[ACCO440, ACCO213...|[GPLL258, GPWL939...|\n",
      "|ACCO350|[COMM305, ACCO218...|[COMP445, ENCS681...|\n",
      "|ACCO355|                  []|[IRST404, BIOL452...|\n",
      "|ACCO360|  [COMM305, ACCO465]|[ACCO455, CEPS109...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSources:\\nhttps://spark.apache.org/docs/latest/api/python/reference/api/pyspark.mllib.evaluation.RankingMetrics.html\\nhttps://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#ranking-systems\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by code1 of similarity then for each code1 compare how many of the pre-reqs are in that list\n",
    "recommender = pickleDF.groupBy(\"code1\").agg(collect_list(col(\"code2\")).alias(\"RecommendedCourses\"))\n",
    "#renamed code1 to Course since that is the origin point that someone would see\n",
    "try:\n",
    "    recommender = recommender.withColumnRenamed(\"code1\", \"Course\")\n",
    "except AnalysisException as e:\n",
    "    print(e)\n",
    "\n",
    "#uses the initial dataset that uses \"ID\",'title','subject', 'catalog', 'career', 'credit', 'description','concepts', 'code, 'requisites' to create our truth values\n",
    "wholeDF = load()\n",
    "truthDF = spark.createDataFrame(wholeDF)\n",
    "truthDF = truthDF.drop(\"ID\",'title','subject', 'catalog', 'career', 'credit', 'description','concepts')\n",
    "\n",
    "#merging our truth values with the predictions\n",
    "merged = truthDF.join(recommender, recommender.Course==truthDF.code)\n",
    "merged = merged.drop(\"Course\")\n",
    "merged.show(10)\n",
    "\n",
    "'''\n",
    "Sources:\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.mllib.evaluation.RankingMetrics.html\n",
    "https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#ranking-systems\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_metrics(df, betaValue):\n",
    "    # Calculate the size of the intersection between RecommendedCourses and requisites\n",
    "    intersection_size = size(array_intersect(col(\"RecommendedCourses\"), col(\"requisites\")))\n",
    "    beta = betaValue\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = when(col(\"RecommendedCourses\").isNotNull(), intersection_size/size(col(\"RecommendedCourses\"))).otherwise(None)\n",
    "    recall = when(col(\"requisites\").isNotNull(), intersection_size/size(col(\"requisites\"))).otherwise(None)\n",
    "    f1_score = when(precision.isNotNull() & recall.isNotNull(), ((1+beta*beta)*precision*recall)/(beta*beta*precision+recall)).otherwise(None)\n",
    "\n",
    "    # Add the new columns\n",
    "    df = df.withColumn(\"Precision\", precision)\n",
    "    df = df.withColumn(\"Recall\", recall)\n",
    "    df = df.withColumn(\"F1-score\", f1_score)\n",
    "    df = df.orderBy(desc(\"F1-score\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1> Evalaution of Content Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prerequisite courses: ['ACCO218', 'ACCO213', 'ACCO240', 'ACCO230', 'ACCO365', 'COMM305', 'COMM308', 'ACCO340', 'ACCO345', 'ACCO213', 'IBUS471', 'ACCO240', 'ACCO470', 'ACCO455', 'COMM217', 'ACCO220', 'COMM305', 'ACCO218', 'ACCO330', 'ACCO310', 'MARK462', 'IBUS471', 'ACCO350', 'ACCO470', 'ACCO355', 'IBUS462', 'ACCO220', 'COMM305', 'ACCO218', 'ACCO320', 'ACCO240', 'ACCO350', 'ACCO400', 'ACCO460', 'ACCO310', 'ACCO410', 'ACCO450', 'ACCO323', 'ACCO326', 'ACCO420', 'ACCO440', 'ACCO213', 'ACCO441', 'ACCO230', 'COMM217', 'COMM305', 'ACCO218', 'COMM301', 'ACCO414', 'COMM226', 'ACCO240', 'COMM217', 'ACCO230', 'ACCO461', 'ACCO320', 'ACCO326', 'ACCO410', 'ACCO320', 'ACCO326', 'ACCO330', 'ACCO303', 'ACCO435', 'ACCO422', 'ACCO330', 'ACCO320', 'COMM401', 'ACCO490', 'ACCO442', 'ACCO441', 'ACCO340', 'COMM315', 'COMM217', 'ACCO230', 'ACCO320', 'ACCO470', 'ACCO360', 'ACCO643', 'ACCO678', 'ACCO613', 'MBA642', 'MBA607', 'MBA642', 'CART211', 'CART251', 'DFAR251', 'DFAR351', 'DFAR350', 'DANC305', 'DANC410', 'ENGR213', 'ENGR233', 'POLI204', 'POLI204', 'ACCO650', 'ACCO651', 'THEA312', 'ACCO650', 'ACCO631', 'GEOG220', 'URBS230', 'ACCO650', 'ACCO643', 'ACCO651', 'ACCO658', 'ACCO608', 'ACCO650', 'ACCO635', 'ACCO653', 'ACCO651', 'ACCO651', 'ACCO652', 'ACCO692', 'ACCO400', 'ACCO652', 'ACCO655', 'ACCO656', 'ACCO659']\n",
      "Recommended courses: ['PHIL621', 'ARTH379', 'ARTT399', 'MUSI322', 'ARTH614', 'ACCO240', 'ARTT398', 'COMM305', 'FINA495', 'PRIN231']\n"
     ]
    }
   ],
   "source": [
    "with open('similarity.pkl', 'rb') as file:\n",
    "    pandas = pickle.load(file)\n",
    "    pickleDF = spark.createDataFrame(pandas)\n",
    "    rdd = spark.read.text(\"content_based_student_courses\").rdd\n",
    "    studentCourses = []\n",
    "    for l in rdd.collect():\n",
    "        studentCourses.append(l[0])\n",
    "    allRequisitesList = []\n",
    "    truthDfAllCourseRequisites = truthDF.filter(col(\"code\").isin(studentCourses)).drop(\"code\")\n",
    "    \n",
    "    for courseRequisitesRow in truthDfAllCourseRequisites.collect():\n",
    "        for courseRequisites in courseRequisitesRow[0]:\n",
    "            allRequisitesList.append(courseRequisites)\n",
    "\n",
    "    print(\"Prerequisite courses: \" + str(allRequisitesList))\n",
    "\n",
    "\n",
    "    filteredDf = pickleDF.filter(col(\"code1\").isin(studentCourses)).drop(\"code1\", \"similarity\").orderBy(col('similarity'), ascending=False).limit(10).withColumnRenamed(\"code2\", \"similar_courses\")\n",
    "    recommendedCourseList = []\n",
    "    for recommendedCourseRow in filteredDf.collect():\n",
    "        for recommendedCourse in recommendedCourseRow:\n",
    "            recommendedCourseList.append(recommendedCourse)\n",
    "\n",
    "    print(\"Recommended courses: \" + str(recommendedCourseList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       avg(F1-score)|\n",
      "+--------------------+\n",
      "|0.023787740164684358|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+\n",
      "|      avg(F1-score)|\n",
      "+-------------------+\n",
      "|0.03149606299212599|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|      avg(F1-score)|\n",
      "+-------------------+\n",
      "|0.06369426751592357|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparisonDf = pd.DataFrame([[allRequisitesList,recommendedCourseList]],columns=['requisites','RecommendedCourses'])\n",
    "\n",
    "comparisonDf = spark.createDataFrame(comparisonDf)\n",
    "calculate_evaluation_metrics(comparisonDf, 1.5).select(\"F1-score\").agg(avg('F1-score')).show(20)\n",
    "calculate_evaluation_metrics(comparisonDf, 1.0).select(\"F1-score\").agg(avg('F1-score')).show(20)\n",
    "calculate_evaluation_metrics(comparisonDf, 0.5).select(\"F1-score\").agg(avg('F1-score')).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Metrics\n",
    "\n",
    "<h2> Precision:\n",
    "\n",
    "This metric represents the proportion of relevant courses among the courses recommended by the model.\n",
    "A high precision means that the model is recommending mostly relevant courses, while a low precision means that the model is recommending many irrelevant courses. In the context of this problem, precision tells you how often the courses recommended by the model are actually requisites for the target course. A precision of 1.0 means that all the courses recommended by the model are requisites for the target course, while a precision of 0.0 means that none of the courses recommended by the model are requisites for the target course.\n",
    "\n",
    "<h2>Recall\n",
    "\n",
    "This metric represents the proportion of relevant courses that are correctly identified by the model. A high recall\n",
    "means that the model is able to identify most of the relevant courses, while a low recall means that the model is missing many relevant courses. In the context of this problem, recall tells you how often the model is able to identify the requisites for the target course. A recall of 1.0 means that the model is able to identify all the requisites for the target course, while a recall of 0.0 means that the model is unable to identify any of the requisites for the target course.\n",
    "\n",
    "<h2>F1-score\n",
    "\n",
    "A high F1-score means that the model is able to achieve high precision and high recall at the same time, while a low F1-score means that the model is struggling to achieve both precision and recall. In this situation, F1-score tells us how well the model is able to identify the requisites for the target course while minimizing the number of irrelevant courses recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(f\"Nb of partitions Cosine: {df_similarity.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Collaborative Filtering Model</h1>\n",
    "Scale of ratings:\n",
    "1-5 (lowest to highest)\n",
    "\n",
    "<h2>How synthetic data was generated:</h2>\n",
    "\n",
    "Since all students take on average 35 courses in their degree, that can be seen as around 0.005% of all courses. This was our first approach at generating all the synthetic data. However, after improving our algorithm, we decided to generate the data using a more realistic approach. We filtered out all different disciplines and generated 10 students for each. On average, for example, a software engineering student will take 60% of all software engineering classes available as there are a lot of electives that are optional. For courses in their program, the student rates the course between 3-5 stars since it is in their domain and they are more likely to like these courses. For courses not in their program, they have a 0.2% of rating the course and these ratings are between 1-5 stars since there is a chance they rate courses outside their degree low. Every student for every program iterate over all courses and apply these rules over all courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First, we need to extract all unique class types\n",
    "codeDf = df.select(substring(df.code, 1,4)).distinct().orderBy(df[\"code\"])\n",
    "courseList = []\n",
    "for i in codeDf.collect():\n",
    "    course = i[0]\n",
    "    if any(char.isdigit() for char in course):\n",
    "        course = course[0:3]\n",
    "    courseList.append(course)\n",
    "courseList = list(dict.fromkeys(courseList))\n",
    "\n",
    "if not os.path.isfile(\"courses.txt\"):\n",
    "    with open(\"courses.txt\", 'w') as f:\n",
    "        f.write('\\n'.join(courseList))\n",
    "\n",
    "allCourses = df.select(\"code\")\n",
    "allCoursesList = [row[0] for row in allCourses.collect()]\n",
    "\n",
    "if not os.path.isfile(\"allCourses.txt\"):\n",
    "    with open(\"allCourses.txt\", \"w\") as f:\n",
    "        for i in range(0, len(allCoursesList)):\n",
    "            f.write(allCoursesList[i] + \"::\" + str(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then, we need to generate synthetic data for our model to train on.\n",
    "# spark = init_spark()\n",
    "rddCourses = spark.read.text(\"courses.txt\").rdd\n",
    "rddAllCourses = spark.read.text(\"allCourses.txt\").rdd\n",
    "splitRdd = rddAllCourses.map(lambda x: x.value.split(\"::\"))\n",
    "\n",
    "studentsPerProgram = 10\n",
    "if not os.path.isfile(\"syntheticData.txt\"):\n",
    "    with open(\"syntheticData.txt\", \"w\") as f:\n",
    "        times = 0\n",
    "        for courseType in rddCourses.collect():\n",
    "            for student in range(0,studentsPerProgram):\n",
    "                for uniqueCourse in splitRdd.collect():\n",
    "                    if re.search(courseType[0], uniqueCourse[0]):\n",
    "                        rand = random.randint(1, 10)\n",
    "                        if rand <= 6:\n",
    "                            rating = random.uniform(3.0,5.0)\n",
    "                            f.write(str(student + times) + \"::\" + str(uniqueCourse[1]) + \"::\" + str(uniqueCourse[0]) + \"::\" + str(rating) + \"\\n\")\n",
    "                    else:\n",
    "                        rand = random.randint(1,500)\n",
    "                        if rand == 1:\n",
    "                            notInProgramRating = random.uniform(1.0, 5.0)\n",
    "                            f.write(str(student + times) + \"::\" + str(uniqueCourse[1]) + \"::\" + str(uniqueCourse[0]) + \"::\" + str(notInProgramRating) + \"\\n\")\n",
    "            times = times + studentsPerProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Duration 3.0755138397216797 seconds\n",
      "+---------+--------------------+\n",
      "|studentId|     recommendations|\n",
      "+---------+--------------------+\n",
      "|        0|[{5327, 4.480903}...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "# spark = init_spark()\n",
    "import time\n",
    "start = time.time()\n",
    "lines = spark.read.text(\"syntheticData.txt\").rdd\n",
    "lineArr = lines.map(lambda line: line.value.split(\"::\"))\n",
    "\n",
    "ratingsRdd = lineArr.map(\n",
    "    lambda line: Row(studentId=int(line[0]), classId=int(line[1]), className=str(line[2]), rating=float(line[3])))\n",
    "\n",
    "ratingsDF = spark.createDataFrame(ratingsRdd)\n",
    "\n",
    "(training, test) = ratingsDF.randomSplit([0.8,0.2])\n",
    "\n",
    "als = ALS(userCol=\"studentId\", itemCol=\"classId\", ratingCol=\"rating\", coldStartStrategy=\"drop\", rank=70, regParam=0.1)\n",
    "model = als.fit(training)\n",
    "\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "#Example for 1 user.\n",
    "userId = 0\n",
    "\n",
    "userRecs = model.recommendForUserSubset(ratingsDF.filter(col(\"studentId\") == userId), 10)\n",
    "\n",
    "print(f\"Model Training Duration {time.time()-start} seconds\")\n",
    "\n",
    "userRecs.show(10)\n",
    "\n",
    "recommendedCoursesCFList = []\n",
    "for user in userRecs.collect():\n",
    "    user_id = user[0]\n",
    "    s = user_id\n",
    "    for item in user[1]:\n",
    "        item_name = training.filter(col(\"classId\") == item[0]).collect()[0][2]\n",
    "        recommendedCoursesCFList.append(item_name)\n",
    "\n",
    "s = \"\"\n",
    "with open(\"classRecommendationsCF.txt\", \"w\") as f:\n",
    "    for rec in userRecs.collect():\n",
    "        user_id = rec[0]\n",
    "        s = user_id\n",
    "        for item in rec[\"recommendations\"]:\n",
    "            item_name = ratingsDF.filter(col(\"classId\") == item[0]).collect()[0][2]\n",
    "            f.write(str(s) + \" | \" + str(item_name) +  \" | \" + str(item[1]) + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "#The code below allows us to generate rating for users with ID > 2660.\n",
    "# ratingsTestDF = ratingsDF.filter(col(\"studentId\") >= 2660)\n",
    "# filteredUserIdDF = ratingsTestDF.drop(\"classId\", \"className\", \"rating\").distinct().orderBy(col(\"studentId\"))\n",
    "\n",
    "# userIdList = []\n",
    "# for userIdRow in  filteredUserIdDF.collect():\n",
    "#     userIdList.append(userIdRow[0])\n",
    "# print(userIdList)\n",
    "\n",
    "# # userIdDF = spark.createDataFrame(userRdd)\n",
    "# userDf = spark.createDataFrame([(uid,) for uid in userIdList], ['studentId'])\n",
    "#\n",
    "# userRecs = model.recommendForUserSubset(userDf, 10)\n",
    "# #\n",
    "# userRecs.show(10)\n",
    "#\n",
    "#\n",
    "# # users = ratingsDataFrame.select(als.getUserCol()).distinct().limit(5)\n",
    "# # userRecs = model.recommendForUserSubset(users, 10)\n",
    "# print(f\"Model Training Duration {time.time()-start} seconds\")\n",
    "# # userRecs.show(5, truncate=False, vertical=True)\n",
    "#\n",
    "# userRecs = model.recommendForUserSubset(ratingsDataFrame.filter(col(\"studentId\") == userId), 10)\n",
    "# # recommendedCoursesCFList = []\n",
    "# # for userRecommendationRow in userRecs.collect():\n",
    "# #     recommendedCoursesCFList = []\n",
    "# #     user_id = userRecommendationRow[0]\n",
    "# #     s = user_id\n",
    "# #     for item in userRecommendationRow[1]:\n",
    "# #         item_name = training.filter(col(\"classId\") == item[0]).collect()[0][2]\n",
    "# #         recommendedCoursesCFList.append(item_name)\n",
    "# #     print(str(recommendedCoursesCFList))\n",
    "#\n",
    "# # s = \"\"\n",
    "# # with open(\"classRecommendationsCF.txt\", \"w\") as f:\n",
    "# #     for rec in userRecs.collect():\n",
    "# #         user_id = rec[0]\n",
    "# #         s = user_id\n",
    "# #         for item in rec[\"recommendations\"]:\n",
    "# #             item_name = ratingsTestDF.filter(col(\"classId\") == item[0]).collect()[0][2]\n",
    "# #             f.write(str(s) + \" | \" + str(item_name) +  \" | \" + str(item[1]) + \"\\n\")\n",
    "# #         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       avg(F1-score)|\n",
      "+--------------------+\n",
      "|0.035681610247026534|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|       avg(F1-score)|\n",
      "+--------------------+\n",
      "|0.047244094488188976|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+\n",
      "|      avg(F1-score)|\n",
      "+-------------------+\n",
      "|0.09554140127388536|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparisonCFDf = pd.DataFrame([[allRequisitesList, recommendedCoursesCFList]], columns=['requisites', 'RecommendedCourses'])\n",
    "\n",
    "comparisonCFDf = spark.createDataFrame(comparisonCFDf)\n",
    "calculate_evaluation_metrics(comparisonCFDf, 1.5).select(\"F1-score\").agg(avg('F1-score')).show(20)\n",
    "calculate_evaluation_metrics(comparisonCFDf, 1.0).select(\"F1-score\").agg(avg('F1-score')).show(20)\n",
    "calculate_evaluation_metrics(comparisonCFDf, 0.5).select(\"F1-score\").agg(avg('F1-score')).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0539415404712085\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of partitions Collaborative Filtering: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nb of partitions Collaborative Filtering: {userRecs.rdd.getNumPartitions()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "13809f5fbb2c71687ac0fbc02129e4c89f53832ed2f3a101566dd09001991f6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
